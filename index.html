<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners -->
  <meta name="description" content="UniDisc: Unified Multimodal Discrete Diffusion">
  <meta property="og:title" content="UniDisc: Unified Multimodal Discrete Diffusion"/>
  <meta property="og:description" content="UniDisc is a unified multimodal discrete diffusion model capable of jointly processing text and images for various tasks."/>
  <meta property="og:url" content="https://yourwebsite.com"/>
  <!-- Path to banner image -->
  <meta property="og:image" content="static/images/banner_image.webp" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="UniDisc: Unified Multimodal Discrete Diffusion">
  <meta name="twitter:description" content="UniDisc is a unified multimodal discrete diffusion model capable of jointly processing text and images for various tasks.">
  <!-- Path to banner image -->
  <meta name="twitter:image" content="static/images/banner_image.webp">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords -->
  <meta name="keywords" content="UniDisc, Multimodal, Discrete Diffusion, Machine Learning, AI, Text Generation, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>UniDisc: Unified Multimodal Discrete Diffusion</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <style>
    .container p {
      padding-top: 1rem;
    }
    /* Add new custom column class */
    .is-five-sixths {
      flex: none;
      width: 87.5%;
    }

    html {
      scroll-behavior: smooth;
    }

    a.anchor-link {
      margin-left: 0.15em;
      color: inherit;
      text-decoration: none;
      opacity: 0;
      transition: opacity 0.2s;
      font-size: 0.6em;
      position: relative;
      top: -0.15em;
      cursor: pointer;
    }

    /* Show the anchor link on hover */
    h2[id]:hover a.anchor-link {
      opacity: 1;
    }

    .progressive-image-container {
      position: relative;
      overflow: hidden;
    }

    .progressive-image {
      opacity: 0;
      transition: opacity 0.3s ease-in;
    }

    .progressive-image.loaded {
      opacity: 1;
    }

    .image-placeholder {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: #f0f0f0;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .spinner {
      width: 40px;
      height: 40px;
      border: 4px solid #f3f3f3;
      border-top: 4px solid #3273dc;
      border-radius: 50%;
      animation: spin 1s linear infinite;
    }

    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }

    /* Update the cached-sentence-builder width and layout */
    #cached-section .cached-sentence-builder {
        flex-grow: 1;
        width: 100%; /* Changed from fixed 512px to 100% */
        padding: 0px 23px; /* Keep existing padding */
        max-width: 512px; /* Add max-width that matches the grid container */
    }

    /* Update the current sentence display */
    #cached-section #cached-current-sentence {
        margin-top: 10px;
        padding: 15px;
        background-color: #f5f5f5;
        border-radius: 8px;
        min-height: 30px;
        font-family: monospace;
        width: 100%; /* Ensure it takes full width of its container */
        box-sizing: border-box; /* Include padding in width calculation */
        white-space: pre-wrap; /* Allow text to wrap */
        word-break: break-word; /* Break long words if needed */
    }

    /* Add styles for the response text */
    #cached-section #cached-response-text {
        margin-top: 8px;
        padding: 15px;
        background-color: #e6f7ff;
        border-radius: 8px;
        min-height: 30px;
        font-family: monospace;
        width: 100%;
        box-sizing: border-box;
        white-space: pre-wrap;
        word-break: break-word;
        display: block; /* Changed from none to block */
    }

    /* Adjust the main container spacing */
    #cached-section .cached-main-container {
        display: flex;
        max-width: 1050px; /* Reduced from 1200px */
        margin: 0 auto; /* Center the container */
        gap: 40px; /* Increased from 20px for more balanced spacing */
        align-items: flex-start;
        padding: 0 20px; /* Add padding to prevent edge touching */
    }

    #cached-section .cached-grid-container {
      position: relative;
      width: 512px;
      height: 512px;
    } 

    /* Add styles for the reset buttons */
    #cached-section .cached-reset-buttons {
      display: flex;
      gap: 10px;
      margin-top: 5px;       
      margin-bottom: 15px;   
      justify-content: flex-start;
      flex-wrap: wrap;     /* Changed from nowrap to wrap to handle different screen sizes */
      overflow-x: visible; /* Changed from auto to visible since we're allowing wrapping */
      padding-bottom: 5px;
      width: 100%;         /* Added to ensure it takes full width */
    }

    #cached-section .cached-reset-button {
      padding: 8px 15px;
      background-color: #f5f5f5;
      border: 1px solid #ddd;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
      transition: all 0.2s ease;
    }

    #cached-section .cached-reset-button:hover {
      background-color: #e0e0e0;
    }

    /* Add styles for the grey overlay */
    #cached-section .cached-grey-overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: #888888; /* Solid grey color */
      z-index: 10; /* Ensure it's above the grid */
      display: none; /* Initially hidden */
    }

    /* Scoped styles for the cached section */
    #cached-section {
      font-family: Arial, sans-serif;
    }
    /* Restore bolder text for headers and word options */
    #cached-section h2,
    #cached-section .cached-word-option {
      font-weight: 700;
    }
    #cached-section .cached-main-container {
      display: flex;
      max-width: 1200px; /* Increased width to accommodate side-by-side layout */
      margin: 0 auto;
      gap: 40px;
      align-items: flex-start;
      padding: 0 20px;
    }
    /* Updated to have input and output sides */
    #cached-section .cached-side {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 10px; /* Reduced from 20px */
      width: 50%;
    }
    /* Left side (input) - left aligned */
    #cached-section .cached-input-side {
      align-items: flex-start;
    }
    /* Right side (output) - center aligned */
    #cached-section .cached-output-side {
      align-items: center;
    }
    #cached-section .cached-side-title {
      text-align: center;
      font-weight: bold;
      margin-bottom: 10px;
      font-size: 1.2rem;
      width: 100%;
    }
    #cached-section .cached-grid-container {
      position: relative;
      width: 512px;
      height: 512px;
      margin: 0 auto;
    }
    #cached-section .cached-image {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #cached-section .cached-grid {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: grid;
      /* TODO: Grid define */
      grid-template-columns: repeat(8, 1fr);
      grid-template-rows: repeat(8, 1fr);
    }
    #cached-section .cached-grid-cell {
      border: 1px solid black;
      transition: background-color 0.1s ease;
    }
    #cached-section .cached-highlighted {
      background-color: rgba(128, 128, 128, 0.9);
    }
    #cached-section .cached-sentence-builder {
      width: 512px; /* Match width with image container */
      padding: 0px 23px; /* Reduced top padding from 20px to 10px */
    }
    #cached-section .cached-output-container {
      width: 512px; /* Match width with image container */
    }
    #cached-section .cached-sentence-row {
      margin: 10px 0; /* Reduced from 15px to 10px */
      display: flex;
      gap: 15px;
      flex-wrap: wrap;
      justify-content: flex-start; /* Align items to the start of the row */
      width: 100%; /* Ensure the row takes full width of its container */
    }
    #cached-section .cached-word-option {
      padding: 5px 8px; /* Reduced padding from 12px 20px */
      cursor: pointer;
      transition: all 0.2s ease;
      color: #666;
      border-radius: 4px;
      font-weight: 600;
      background: #f5f5f5;
      margin-bottom: 5px; /* Add bottom margin for better spacing when wrapped */
      font-size: 0.8rem; /* Added smaller font size */
    }
    #cached-section .cached-word-option:hover {
      color: #000;
      font-weight: 600;
      background: #e5e5e5;
    }
    #cached-section .cached-word-option.cached-selected {
      color: #886a6a;
      font-weight: 600;
      background: #e0e0e0;
    }
    #cached-section .cached-text-display {
      margin-top: 20px;
      padding: 15px;
      background-color: #f5f5f5;
      border-radius: 8px;
      min-height: 30px;
      font-family: monospace;
      width: 100%;
      box-sizing: border-box;
      white-space: pre-wrap;
      word-break: break-word;
    }
    #cached-section .cached-output-display {
      margin-top: 10px;
      padding: 15px;
      background-color: #e6f7ff;
      border-radius: 8px;
      min-height: 30px;
      font-family: monospace;
      width: 100%;
      box-sizing: border-box;
      white-space: pre-wrap;
      word-break: break-word;
    }
    #cached-section .cached-grey-overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: #888888;
      z-index: 10;
      display: none;
    }
    #cached-section .cached-reset-buttons {
      display: flex;
      gap: 10px;
      margin-top: 5px;       
      margin-bottom: 15px;   
      justify-content: flex-start;
      flex-wrap: nowrap;     /* Prevent wrapping */
      overflow-x: auto;      /* Allow horizontal scrolling if needed */
      padding-bottom: 5px;   /* Add space for potential scrollbar */
    }
    #cached-section .cached-reset-button {
      padding: 8px 15px;
      background-color: #f5f5f5;
      border: 1px solid #ddd;
      border-radius: 4px;
      cursor: pointer;
      font-size: 12px;
      transition: all 0.2s ease;
    }
    #cached-section .cached-reset-button:hover {
      background-color: #e0e0e0;
    }
    #cached-section .cached-mask-size-container {
      display: flex;
      align-items: center;
      margin-left: 10px;
    }
    #cached-section .cached-mask-size-label {
      font-size: 12px;
      margin-right: 5px;
      white-space: nowrap;
    }
    #cached-section .cached-mask-size-input {
      width: 50px;
      padding: 6px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-size: 12px;
      text-align: center;
    }
    #cached-section .cached-output-container h2 {
      margin-top: 5px;
      /* margin-bottom: 10px; */
    }
    
    /* Add new styles for the sentence groups layout */
    #cached-section .cached-sentence-group {
      display: flex;
      gap: 10px;
      margin-bottom: 0px;
      flex-wrap: wrap;
    }
    
    #cached-section .cached-sentence-row {
      margin: 4px 0px; /* Reduced from 10px to 5px */
      display: flex;
      gap: 6px;
      flex-wrap: wrap;
      justify-content: flex-start;
      width: calc(50% - 10px); /* Take up roughly half minus gap space */
      min-width: 200px; /* Ensure minimum width for readability */
    }
    
    @media (max-width: 768px) {
      #cached-section .cached-sentence-row {
        width: 100%; /* Full width on small screens */
      }
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>

    <!-- Header Section -->
    <section class="hero">
      <div class="hero-body" style="padding-bottom: 1.5rem;">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">UniDisc: Unified Multimodal Discrete Diffusion</h1>
              

                <div class="is-size-5 publication-authors">
                  <span class="author-block">Anonymous Authors</span>
                </div>
  
                
  
              
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section id="flipping-images-section">
      <style>
        #flipping-images-section {
          font-family: sans-serif;
          margin: 2rem auto;            /* Center the section vertically */
          max-width: 100%;              /* Make it full screen width */
          padding: 0 0px;              /* Add left/right padding */
          overflow: hidden;
        }
        #flipping-images-section .flip-card-container {
          display: flex;
          flex-wrap: wrap;
          gap: 0;
          justify-content: center;
          padding: 0;
          margin: 0;
          width: 100%;
          line-height: 0; /* Eliminate whitespace between inline elements */
          font-size: 0;
        }
        #flipping-images-section .flip-card {
          background-color: transparent;
          width: 20%; /* 5 cards per row */
          aspect-ratio: 520/720; /* Match image dimensions */
          perspective: 1000px;
          cursor: pointer;
          flex: 0 0 20%;
          position: relative;
          margin: 0;
          padding: 0;
          font-size: 16px;
          vertical-align: top;
        }
        #flipping-images-section .flip-card-inner {
          position: relative;
          width: 100%;
          height: 100%;
          transition: transform 0.6s;
          transform-style: preserve-3d;
          margin: 0;
        }
        #flipping-images-section .flip-card.flipped .flip-card-inner {
          transform: rotateY(180deg);
        }
        #flipping-images-section .flip-card-front,
        #flipping-images-section .flip-card-back {
          position: absolute;
          width: 100%;
          height: 100%;
          backface-visibility: hidden;
          overflow: hidden;
          margin: 0;
          padding: 0;
        }
        #flipping-images-section .flip-card-front {
          z-index: 2;
        }
        #flipping-images-section .flip-card-back {
          transform: rotateY(180deg);
          z-index: 1;
          position: relative;
        }
        #flipping-images-section .input-label {
          position: absolute;
          top: 10px;
          left: 10px;
          background-color: rgba(0, 0, 0, 0.5);
          color: white;
          padding: 10px 8px;
          border-radius: 4px;
          font-size: 12px;
          opacity: 0.8;
          z-index: 3;
        }
        #flipping-images-section figure {
          margin: 0;
          padding: 0;
          width: 100%;
          height: 100%;
          display: flex;
          flex-direction: column;
          line-height: 0;
          position: relative;
        }
        #flipping-images-section img {
          width: 100%;
          height: 100%;
          object-fit: contain; /* Changed from cover to contain */
          display: block;
          margin: 0;
          padding: 0;
          border: 0;
        }
        #flipping-images-section figcaption {
          display: block;
          padding: 8px;
          font-size: 14px;
          color: #333;
          text-align: center;
          background: #f5f5f5;
          margin: 0;
          line-height: normal;
        }
        
        /* New styles for transparent grey overlay on the *back* images */
        #flipping-images-section .back-image-container {
          position: relative;
          height: 100%;
        }
        #flipping-images-section .back-image-overlay {
          position: absolute;
          top: 0;
          left: 0;
          width: 100%;
          height: 100%;
          background-color: rgba(128, 128, 128, 0.7); /* semi-transparent grey */
          pointer-events: none;
          z-index: 1;
        }
        /* Ensure the image sits below the overlay */
        #flipping-images-section .flip-card-back figure img {
          position: relative;
          z-index: 0;
        }
        /* Keep the caption above the overlay */
        #flipping-images-section .flip-card-back figure figcaption {
          position: relative;
          z-index: 2;
        }
      </style>
      <div class="flip-card-container"></div>
      <script src="static/js/flip_cards.js"></script>
    </section>

  <!-- Teaser Image -->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <picture>
          <source srcset="static/images/main_fidelity.webp" type="image/webp">
          <img src="static/images/main_fidelity.webp" alt="Joint Inpainting">
        </picture>
        <h2 class="subtitle has-text-centered">
        <div style="margin-top: 10px;">
          UniDisc jointly inpainting unseen image-text pairs. This ability is not possible with prior models such as T2I diffusion or AR models.
        </div>
        </h2>
      </div>
    </div>
  </section> -->

  <!-- Abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 id="abstract" class="title is-3">Abstract
            <a href="#abstract" class="anchor-link">
              <i class="fas fa-link"></i>
            </a>
          </h2>
          <div class="content has-text-justified">
            <p>
              Multimodal generative models that can understand and generate across multiple modalities are dominated by autoregressive (AR) approaches, which process tokens sequentially from left to right, or top to bottom. These models jointly handle images, text, video, and audio for various tasks such as image captioning, question answering, and image generation. While AR models have been highly successful in the text domain, they have been found suboptimal for processing images, videos, and audio due to the high correlation between adjacent tokens which waste inference-time compute by separately predicting each one. In this work, we explore discrete diffusion models as a unified generative formulation in the joint text and image domain, building upon their recent success in the text domain alone. Discrete diffusion models offer several advantages over AR models, including improved control over quality versus diversity of generated samples, the ability to perform joint multimodal inpainting (across both text and image domains), and greater controllability in generation through guidance. Leveraging these benefits, we present the first <strong>Uni</strong>fied Multimodal <strong>Disc</strong>rete Diffusion (UniDisc) model, which is capable of jointly processing text and images for a variety of downstream tasks. We compare UniDisc to multimodal AR models of similar capacity, demonstrating that UniDisc outperforms them in terms of both performance and inference-time compute, enhanced controllability, editability, inpainting, and flexible trade-off of inference time versus generation quality.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section id="cached-section" class="section">
    <div class="cached-main-container">
      <!-- Left side - Input -->
      <div class="cached-side cached-input-side">
        <div class="cached-side-title">Input</div>
        <div class="cached-grid-container">
          <img src="static/images/giraffe.png" alt="Input Image" class="cached-image" id="cached-input-image">
          <div id="cached-grid" class="cached-grid"></div>
          <div id="cached-grey-overlay" class="cached-grey-overlay"></div>
        </div>
        
        <div class="cached-sentence-builder">
          <div class="cached-reset-buttons">
            <button id="cached-reset-image" class="cached-reset-button">Restore Image</button>
            <button id="cached-clear-mask" class="cached-reset-button">Clear Mask</button>
            <button id="cached-remove-image" class="cached-reset-button">Fully Mask</button>
            <div class="cached-mask-size-container" style="display: none;">
              <label for="cached-mask-size" class="cached-mask-size-label">Mask Size:</label>
              <input type="number" id="cached-mask-size" class="cached-mask-size-input" min="2" max="8" value="7">
            </div>
          </div>
          
          <h2 style="margin-bottom: 5px;">Build your sentence:</h2>
          <div class="cached-sentence-group">
            <div class="cached-sentence-row">
              <span class="cached-word-option" data-row="0" data-word="a tall">a tall</span>
              <span class="cached-word-option" data-row="0" data-word="a happy">a happy</span>
              <span class="cached-word-option" data-row="0" data-word="&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;">&lt;mask&gt;</span>
            </div>
            <div class="cached-sentence-row">
              <span class="cached-word-option" data-row="1" data-word="giraffe">giraffe</span>
              <span class="cached-word-option" data-row="1" data-word="puppy">puppy</span>
              <span class="cached-word-option" data-row="1" data-word="&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;">&lt;mask&gt;</span>
            </div>
          </div>
          <div class="cached-sentence-group">
            <div class="cached-sentence-row">
              <span class="cached-word-option" data-row="2" data-word="wearing a">wearing a</span>
              <span class="cached-word-option" data-row="2" data-word="with a">with a</span>
              <span class="cached-word-option" data-row="2" data-word="&lt;mask&gt;&lt;mask&gt;">&lt;mask&gt;</span>
            </div>
            <div class="cached-sentence-row">
              <span class="cached-word-option" data-row="3" data-word="green shirt">green shirt</span>
              <span class="cached-word-option" data-row="3" data-word="top hat">top hat</span>
              <span class="cached-word-option" data-row="3" data-word="&lt;mask&gt;&lt;mask&gt;">&lt;mask&gt;</span>
            </div>
          </div>
          <div class="cached-sentence-group">
            <div class="cached-sentence-row">
              <span class="cached-word-option" data-row="4" data-word=", detailed portrait">detailed</span>
              <span class="cached-word-option" data-row="4" data-word=", cartoon style">cartoon</span>
              <span class="cached-word-option" data-row="4" data-word="&lt;mask&gt;&lt;mask&gt;">&lt;mask&gt;</span>
            </div>
          </div>
          <div id="cached-current-sentence" class="cached-text-display">Click word pairs above to build your sentence!</div>
        </div>
      </div>
      
      <!-- Right side - Output -->
      <div class="cached-side cached-output-side">
        <div class="cached-side-title">Output</div>
        <div class="cached-grid-container">
          <img src="static/images/giraffe.png" alt="Output Image" class="cached-image" id="cached-output-image">
          <div id="cached-output-overlay" class="cached-grey-overlay" style="display: block;"></div>
        </div>
        
        <div class="cached-output-container">
          <h2>Model Response:</h2>
          <div id="cached-response-text" class="cached-output-display">Select words and interact with the input image to see results here.</div>
        </div>
      </div>
    </div>
    <script src="static/js/cached_section.js"></script>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">
          Demo Video
          <a href="#demo_video" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
  
        <div class="columns is-centered">
          <div class="column is-five-sixths has-text-centered">
            <video width="100%" controls loop muted style="border-radius: 12px;">
              <source src="static/videos/demo_video.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
        <p class="has-text-centered"><b>Demo Video:</b> UniDisc can jointly inpaint images and text pairs.</p>
      </div>
    </div>
  </section>

  <section class="hero is-small pt-6 pb-3">
    <div class="hero-body">
      <div class="container">
        <h2 id="overall_architecture" class="title is-3 has-text-centered">
          UniDisc Overview
          <a href="#overall_architecture" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="padding-top: 20px;">
          <div class="column is-five-sixths has-text-centered">
            <picture>
              <source srcset="static/images/method_figure.png" type="image/png">
              <img src="static/images/method_figure.png" alt="Modality Plot">
            </picture>
            <p style="padding-bottom: 30px;">UniDisc is a unified multimodal discrete diffusion model that can jointly process and generate text and images. First, each modality is converted into a sequnece of discrete tokens and we randomly replace a subset of these tokens with the [MASK] token according to a noise schedule and denoted in the figure with grey boxes. We jointly denoise the image and text and supervise with a weighted cross-entropy loss. At inference time we begin with a set of [MASK] tokens and iteratively unmask tokens.</p>
          </div>
        </div>
        <video width="100%" autoplay loop muted playsinline>
          <source src="static/videos/unidisc_generation.mov" type="video/mp4">
          Your browser does not support the video tag.
        </video>

        
      </div>
    </div>
  </section>

  <section class="hero is-small pt-5 pb-6 is-light">
    <div class="hero-body">
      <div class="container">
        <h2 id="scaling_laws" class="title is-3 has-text-centered">
         UniDisc Training Scaling Laws
          <a href="#scaling_laws" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="padding-top: 1.5rem;">
          <div class="column is-five-sixths has-text-centered">
            <div class="columns">
              <div class="column">
                <picture>
                  <source srcset="static/images/scaling.png" type="image/png">
                  <img src="static/images/scaling.png" alt="Scaling Laws">
                </picture>
              </div>
              <div class="column">
                <picture>
                  <source srcset="static/images/scaling_nar_ar.png" type="image/png">
                  <img src="static/images/scaling_nar_ar.png" alt="NAR vs AR Scaling">
                </picture>
              </div>
            </div>
            <p>Scaling Analysis for AR and UniDisc models: (Left) IsoFLOP curves for UniDisc, plotting varying model size for a fixed FLOP budget. (Right) Estimating optimal parameter size for each budget - minima of fitted parabola, we plot scaling laws for both AR and UniDisc. We find 13.2x more compute is required for UniDisc to achieve the same overall loss as AR.</p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="hero is-small  pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="cfg_ablation" class="title is-3 has-text-centered">
          UniDisc vs. Autoregressive at Inference
          <a href="#cfg_ablation" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="padding-top: 1.5rem;">
          <div class="column is-five-sixths has-text-centered">
            <video width="100%" autoplay loop muted playsinline>
              <source src="static/videos/uni_v_ar.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          
        </div>
        <p class="has-text-centered"> UniDisc can generate images with a lot lesser forward passes than AR models.</p>
        <div class="columns is-centered" style="margin-top: 2rem;">
          <div class="column is-five-sixths has-text-centered">
            <div style="display: flex; justify-content: center; gap: 1px;">
              <picture>
                <source srcset="static/images/cfg_fid.webp" type="image/webp">
                <img src="static/images/cfg_fid.webp" alt="Concept Generation" style="width: 95%;">
              </picture>
              <picture>
                <source srcset="static/images/cfg_clip_score.webp" type="image/webp">
                <img src="static/images/cfg_clip_score.webp" alt="Concept Generation" style="width: 95%;"> 
              </picture>
            </div>
            <p>Conditional generation results for both FID and CLIP metrics, across a range of CFG values.} We find that AR is more sensitive to the CFG weighting, with a narrower optimal range. We find UniDisc achieves better FiD and CLIP score than Unifiied Autoregressive models such as Chameleon.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="zero_shot_editing" class="title is-3 has-text-centered">
          Zero-shot Multimodal Editing with UniDisc
          <a href="#zero_shot_editing" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="padding-top: 1.5rem;">
          <div class="column is-five-sixths has-text-centered">
            <video width="100%" autoplay loop muted playsinline>
              <source src="static/videos/unidisc_edit.mov" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            <p></p>
          </div>
        </div>
        <div class="columns is-centered" style="padding-top: 3.5rem;">
          <div class="column is-five-sixths has-text-centered">
            <h3 class="subtitle">Zero-shot Multimodal Editing Results</h3>
            <picture>
              <source srcset="static/images/automatic_editing_crop.png" type="image/png">
              <img src="static/images/automatic_editing_crop.png" alt="Image Inpainting">
            </picture>
            <p>UniDisc can automatically improve a user provided image and caption. We adopt a best-of-n sampling strategy with n distinct noise masks. We unroll each generation until completion and use the model's own likelihood to determine select the best generation.</p>
            <br>
            <p>We augment real images by overlaying random objects from the COCO dataset. Similarly, we augment captions by asking an LLM to generate purposely incorrect variations. We then randomly mask the image and text inputs and unmask as described above, automatically removing these undesired image artifacts and generating the correct caption. There is no human intervention or masking in any examples. In the final row, we fix the text prompt, and only allow updates to the image.</p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- <section class="hero is-small is-light pt-4 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="multimodal_caching" class="title is-3 has-text-centered">
          Multimodal Caching
          <a href="#multimodal_caching" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>

        <div class="columns is-centered">
          <div class="column is-three-fifths has-text-centered">
            <picture>
              <source srcset="static/images/modality_plot.webp" type="image/webp">
              <img src="static/images/modality_plot.webp" alt="Modality Plot">
            </picture>
            <p style="padding-bottom: 30px;">To take advantage of this, we design a novel multimodal caching mechanism that allows UniDisc to reuse the same denoising steps for specific modalities, reducing overall inference time.</p>
            <picture>
              <source srcset="static/images/architecture_diagram.webp" type="image/webp">
              <img src="static/images/architecture_diagram.webp" alt="Text Generation from Image">
            </picture>
            <p>We maintain different noising schedules for image and text tokens, effectively setting a larger \(dt_{\text{image}}\) and a smaller \(dt_{\text{text}}\).</p>
          </div>
        </div>
        
      </div>
    </div>
  </section> -->

 
  <section class="hero  is-small pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="generation_analysis" class="title is-3 has-text-centered">
          Generation Analysis
          <a href="#generation_analysis" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="margin-top: 2rem;">
          <div class="column is-five-sixths has-text-centered">
            <picture>
              <source srcset="static/images/denoising_viz_new.png" type="image/png">
              <img src="static/images/denoising_viz_new.png" alt="Joint Infilling">
            </picture>
            <p>Intermediate Steps during Joint Infilling of Image and Text. UniDisc jointly infills both image and text during generation.</p>
          </div>
        </div>

        <div class="columns is-centered" style="margin-top: 3rem;">
          <div class="column is-five-sixths has-text-centered">
            <h3 class="subtitle" style="margin-bottom: 2.0rem;">Uniform Concept Generation</h3>
            <picture>
              <source srcset="static/images/seg_viz_v2.webp" type="image/webp">
              <img src="static/images/seg_viz_v2.webp" alt="Concept Generation">
            </picture>
            <p>To quantitatively analyze the generation order, we use an language-grounded segmentation model (Grounded SAM 2) to segment the image given the text prompt. We then record the order of token decoding when using confidence-based sampling and plot the progression of each region. We observe that the model generates uniformly over concepts and modalities. In AR this is not possible as the model must generate in a specific order (e.g., text first, then raster-order), and thus the model cannot jointly reason over modalities and multiple parts of the image.</p>
          </div>
        </div>

      </div>
    </div>
  </section>



 

  <section class="hero is-small pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="cfg_unidisc_ar_analysis" class="title is-3 has-text-centered">
          Classifier-Free Guidance Analysis
          <a href="#cfg_unidisc_ar_analysis" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered">
          <div class="column is-five-sixths">
            <div class="columns">
              <!-- Left column for the graph -->
              <div class="column is-half">
                <picture>
                  <source srcset="static/images/cfg_dist_vs_pct_tokens.png" type="image/png">
                  <img src="static/images/cfg_dist_vs_pct_tokens.png" alt="CFG Distance vs Percent Tokens">
                </picture>
                <p class="has-text-centered">L2 distance between unconditional and conditional logits on currently masked tokens as sampling steps increase.</p>
              </div>
              
              <!-- Right column for the table -->
              <div class="column is-half" style="margin-top: 5.5rem;">
                <table class="table is-bordered is-centered" style="margin: 0 auto;">
                  <thead>
                    <tr>
                      <th>Steps</th>
                      <th>CLIP Score</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>[1-3]</td>
                      <td>0.301</td>
                    </tr>
                    <tr>
                      <td>[12-14]</td>
                      <td>0.293</td>
                    </tr>
                    <tr>
                      <td>[22-24]</td>
                      <td>0.283</td>
                    </tr>
                    <tr>
                      <td><strong>All (24)</strong></td>
                      <td>0.312</td>
                    </tr>
                  </tbody>
                </table>
                <p class="has-text-centered">Comparing CLIP scores by applying CFG only on specific steps. This shows CFG has the most impact on the initial denoising steps (total steps = 24).</p>
              </div>
            </div>
            <p class="has-text-centered">CFG significantly impacts the performance difference between UniDisc and Autoregressive model. To analyze this, we compare UniDisc with an AR model. The left figure shows the difference between conditional and unconditional predictions at various decoding stages. We observe that (a) the difference decreases as more tokens are decoded and (b) UniDisc maintains higher logit distances than AR throughout the process.

             We believe UniDisc's flexibility to generate tokens in any order allows it to keep a higher logit distance between unconditional and conditional predictions, thus allowing it to leverage CFG more effectively. The right table supports this, showing that applying CFG in just the first 3 steps achieves similar CLIP scores to applying it throughout all steps, while later-step CFG has minimal impact, which also correlates with the conditional and unconditional distance reducing as more tokens are decoded.
              </p>
          </div>
        </div>
        <div class="columns is-centered">
          <div class="column is-five-sixths has-text-centered">
            <h3 class="subtitle">Qualitative Effect of Classifier-Free Guidance</h3>
            <picture>
              <source srcset="static/images/unidisc_cfg.png" type="image/png">
              <img src="static/images/unidisc_cfg.png" alt="Classifier-Free Guidance" style="margin-bottom: -0.6rem;">
            </picture>
            <p style="margin-bottom: -0.8rem;">Effect of classifier-free guidance in UniDisc, from left to right.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <h2 id="cfg_visualization" class="title is-3 has-text-centered">
          Qualitative CFG Visualization
          <a href="#cfg_visualization" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <picture poster="" id="steve" height="100%">
              <img src="static/images/UniDisc_cur.001.jpeg" alt="UniDisc_cur.001.jpeg">
            </picture>
          </div>
          <div class="item item-chair-tp">
            <picture poster="" id="chair-tp" height="100%">
              <img src="static/images/UniDisc_cur.002.jpeg" alt="UniDisc_cur.002.jpeg">
            </picture>
          </div>
          <div class="item item-shiba">
            <picture poster="" id="shiba" height="100%">
              <img src="static/images/UniDisc_cur.003.jpeg" alt="UniDisc_cur.003.jpeg">
            </picture>
          </div>
        </div>
        <p class="has-text-centered">
          Visualization of the conditional and unconditional prediction, p(x_0) of UniDisc. Click to the right to see the prediction change as the denoising step increases. We see that at the 0th timestep, the unconditional prediction significantly differs from the conditional prediction. However, at just the 3rd step, the unconditional prediction appears to closely match the conditional prediction, demonstrating why autoregressive models obtain a smaller benefit compared to discrete diffusion models. For a quantitative analysis, please refer to <a href="#cfg_unidisc_ar_analysis" target="_blank" style="font-weight: bold; color: #3273dc; text-decoration: underline;">the CFG Analysis Section</a>.
        </p>
      </div>
    </div>
  </section>

  <!-- New Qualitative Generations Section -->
  <section class="hero is-small pt-5 pb-6 is-light">
    <div class="hero-body">
      <div class="container">
        <h2 id="qualitative_generations" class="title is-3 has-text-centered">
          Qualitative Text Generations with Varying Steps/Token Ratio
          <a href="#qualitative_generations" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="margin-top: 2rem;">
          <div class="column is-full">
            <div class="columns is-multiline is-mobile">
              <!-- Image 0 -->
              <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile generation-column">
                <picture>
                  <source srcset="static/images/img0.png" type="image/png">
                  <img src="static/images/img0.png" alt="Scaling Laws">
                </picture>
                <div class="caption-container">
                  <p><strong>0.15 steps/token:</strong> contributions the forest sun Sun fruit untouchical undorn trees unicorn prancing through beauty fruit fruit fruit under dapp sun sun unappear lightlight field on fruit fruit sun everywhere</p>
                  <p><strong>0.50 steps/token:</strong> sunlight breaking through a forest of trees and into a cushappled meadow where a unicorn runs free among the fruitland vegetables</p>
                  <p><strong>1.00 steps/token:</strong> A lush green forest with a sun blue sky brightly, shining through the trees and casting long shadows. A unicorn with a spiraled horn and a green mane is visible in the foreground. In the bottom right corner, there are various fruits and leaves including apples, oranges. There are also some yellow flowers scattered in the lush green grass.</p>
                </div>
              </div>
              <!-- Image 1 -->
              <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile generation-column">
                <picture>
                  <source srcset="static/images/img1.png" type="image/png">
                  <img src="static/images/img1.png" alt="Generation 1">
                </picture>
                <div class="caption-container">
                  <p><strong>0.15 steps/token:</strong> panda with waving paw wavingaving nature panda withaving human thumb weaving Hawaiian print shirt</p>
                  <p><strong>0.50 steps/token:</strong> cute adult panda in a Hawaiian shirt waving baby gorilla in a Hawaiian shirt</p>
                  <p><strong>1.00 steps/token:</strong> Panda with floral shirt, waving to zoo visitor, tropical background</p>
                </div>
              </div>
              <!-- Image 2 -->
              <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile generation-column">
                <picture>
                  <source srcset="static/images/img2.png" type="image/png">
                  <img src="static/images/img2.png" alt="Generation 2">
                </picture>
                <div class="caption-container">
                  <p><strong>0.15 steps/token:</strong> intricatecut clock clock clock clock clock drawing drawing clock drawing drawing drawing detailed carv stone cathedral building facade</p>
                  <p><strong>0.50 steps/token:</strong> etching of a medieval cathedral clock's intricate stone carvings</p>
                  <p><strong>1.00 steps/token:</strong> Detailed drawing of clock on the facade of a historic, medieval-style monastery, with intricate stone carvings.</p>
                </div>
              </div>
              <!-- Image 3 -->
              <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile generation-column">
                <picture>
                  <source srcset="static/images/img3.png" type="image/png">
                  <img src="static/images/img3.png" alt="Generation 3">
                </picture>
                <div class="caption-container">
                   <p><strong>0.15 steps/token:</strong> futurical burgereburgerurgerurger azure motor bike neon cityss chrome</p>
                   <p><strong>0.50 steps/token:</strong> Silver motorcycle, hamburger sculpture, neon signs, cyberpunk cityscape</p>
                   <p><strong>1.00 steps/token:</strong> A metallic hamburger motorcycle on a neon-lit cityscape</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="t2i_generations" class="title is-3 has-text-centered">
          Qualitative Image Generations with Varying Steps/Token Ratio
          <a href="#t2i_generations" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <style>
          #t2i_generations .caption-column {
            display: flex;
            flex-direction: column;
            align-items: center; /* Center content horizontally */
          }
          #t2i_generations .caption-text {
            font-weight: bold;
            text-align: center;
            margin-bottom: 1.5rem; /* Space below caption */
            height: 150px; /* Increased fixed height significantly */
            display: flex; /* Use flexbox for vertical centering */
            align-items: center; /* Vertically center text */
            justify-content: center; /* Horizontally center text (redundant with text-align, but safe) */
            width: 100%; /* Ensure it takes full width */
          }
          #t2i_generations .image-set {
            width: 100%;
          }
          #t2i_generations .image-item {
            margin-bottom: 1rem; /* Space below each image and its label */
            text-align: center;
          }
          #t2i_generations .image-label {
            font-size: 0.9rem;
            color: #555;
            margin-bottom: 0.25rem;
            font-weight: bold;
          }
          #t2i_generations .generation-image {
            max-width: 100%;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
          }
          #t2i_generations .placeholder-image {
             width: 100%; 
             aspect-ratio: 1 / 1; /* Maintain square aspect ratio */
             background-color: #f0f0f0; 
             display: flex; 
             align-items: center; 
             justify-content: center; 
             color: #aaa; 
             font-style: italic;
             margin-left: auto;
             margin-right: auto;
             max-width: 256px; /* Limit placeholder size */
             box-sizing: border-box; /* Include padding/border in size */
             padding: 10px;
          }

        </style>
        <div class="columns is-centered is-multiline" style="margin-top: 2rem;">
          <!-- Column 1: t2i_0 -->
          <div class="column is-one-fifth caption-column">
            <p class="caption-text">Prompt: "a cozy cabin's interior, including a wooden bed and a stone fireplace"</p>
            <div class="image-set">
              <div class="image-item">
                <p class="image-label">0.01 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_0_img0.png" type="image/png">
                  <img src="static/images/t2i_0_img0.png" alt="Cabin interior 0.15" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.03 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_0_img1.png" type="image/png">
                  <img src="static/images/t2i_0_img1.png" alt="Cabin interior 0.50" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.05 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_0_img2.png" type="image/png">
                  <img src="static/images/t2i_0_img2.png" alt="Cabin interior 0.75" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.10 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_0_img3.png" type="image/png">
                  <img src="static/images/t2i_0_img3.png" alt="Cabin interior 1.00" class="generation-image">
                </picture>
              </div>
            </div>
          </div>

          <!-- Column 2: t2i_2 -->
          <div class="column is-one-fifth caption-column">
            <p class="caption-text">Prompt: "a sculpture of a bird by Paolo Uccello"<br><br></p>
            <div class="image-set">
              <div class="image-item">
                <p class="image-label">0.01 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_2_img0.png" type="image/png">
                  <img src="static/images/t2i_2_img0.png" alt="Bird sculpture 0.15" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.03 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_2_img1.png" type="image/png">
                  <img src="static/images/t2i_2_img1.png" alt="Bird sculpture 0.50" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.05 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_2_img2.png" type="image/png">
                  <img src="static/images/t2i_2_img2.png" alt="Bird sculpture 0.75" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.10 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_2_img3.png" type="image/png">
                  <img src="static/images/t2i_2_img3.png" alt="Bird sculpture 1.00" class="generation-image">
                </picture>
              </div>
            </div>
          </div>

          <!-- Column 3: t2i_3 -->
          <div class="column is-one-fifth caption-column">
            <p class="caption-text">Prompt: "colorful small to massive vases artfully arranged in front of a colorful street art mural"</p>
            <div class="image-set">
              <div class="image-item">
                <p class="image-label">0.01 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_3_img0.png" type="image/png">
                  <img src="static/images/t2i_3_img0.png" alt="Vases and mural 0.15" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.03 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_3_img1.png" type="image/png">
                  <img src="static/images/t2i_3_img1.png" alt="Vases and mural 0.50" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.05 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_3_img2.png" type="image/png">
                  <img src="static/images/t2i_3_img2.png" alt="Vases and mural 0.75" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.10 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_3_img3.png" type="image/png">
                  <img src="static/images/t2i_3_img3.png" alt="Vases and mural 1.00" class="generation-image">
                </picture>
              </div>
            </div>
          </div>

          <!-- Column 4: t2i_4 -->
          <div class="column is-one-fifth caption-column">
            <p class="caption-text">Prompt: "A stylized digital rendering of Mount Olympus from ancient Greek mythology"</p>
            <div class="image-set">
              <div class="image-item">
                <p class="image-label">0.01 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_4_img0.png" type="image/png">
                  <img src="static/images/t2i_4_img0.png" alt="Mount Olympus 0.15" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.03 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_4_img1.png" type="image/png">
                  <img src="static/images/t2i_4_img1.png" alt="Mount Olympus 0.50" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.05 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_4_img2.png" type="image/png">
                  <img src="static/images/t2i_4_img2.png" alt="Mount Olympus 0.75" class="generation-image">
                </picture>
              </div>
              <div class="image-item">
                <p class="image-label">0.10 steps/token</p>
                <picture>
                  <source srcset="static/images/t2i_4_img3.png" type="image/png">
                  <img src="static/images/t2i_4_img3.png" alt="Mount Olympus 1.00" class="generation-image">
                </picture>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-small pt-4 pb-6">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 id="multimodal_caching" class="title is-3 has-text-centered">
          Multimodal Caching
          <a href="#multimodal_caching" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>

        <div class="columns is-centered">
          <div class="column is-three-fifths has-text-centered">
            <picture>
              <source srcset="static/images/modality_plot.webp" type="image/webp">
              <img src="static/images/modality_plot.webp" alt="Modality Plot">
            </picture>
            <p style="padding-bottom: 30px;">To take advantage of this, we design a novel multimodal caching mechanism that allows UniDisc to reuse the same denoising steps for specific modalities, reducing overall inference time.</p>
            <picture>
              <source srcset="static/images/architecture_diagram.webp" type="image/webp">
              <img src="static/images/architecture_diagram.webp" alt="Text Generation from Image">
            </picture>
            <p>We maintain different noising schedules for image and text tokens, effectively setting a larger \(dt_{\text{image}}\) and a smaller \(dt_{\text{text}}\).</p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-small is-light pt-4 pb-6">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 id="multimodal_caching" class="title is-3 has-text-centered">
          Caching Inference Analysis
          <a href="#multimodal_caching" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered">
          <div class="column is-three-fifths has-text-centered">
            <picture>
              <source srcset="static/images/cache_time.png" type="image/png">
              <img src="static/images/cache_time.png" alt="Text Generation from Image">
            </picture>
            <p>Figure 27: Latency vs. Seq Length for our caching approach - image-to-text tokens ratio = 1/4. We empirically find k = 10
              from Fig. 7 based on the saturation steps for image to text.</p>
          </div>
        </div>
      </div>
    </div>
  </section>
    
  <!-- New Ablation Study Section -->
  <section class="hero is-small pt-5 pb-6">
    <div class="hero-body">
      <div class="container">
        <h2 id="ablation_study" class="title is-3 has-text-centered">
          Design Choices Ablation Study
          <a href="#ablation_study" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="margin-top: 2rem;">
          <div class="column is-two-thirds"> <!-- Adjusted column width -->
            <table class="table is-bordered is-striped is-hoverable is-fullwidth">
              <thead>
                <tr>
                  <th class="has-text-centered">Configuration</th>
                  <th class="has-text-centered">DataComp1B Validation PPL</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>UniDisc</td>
                  <td class="has-text-centered">93.8</td>
                </tr>
                <tr>
                  <td>w/o QK Norm</td>
                  <td class="has-text-centered">92.7</td>
                </tr>
                <tr>
                  <td>w/ Zero-linear init</td>
                  <td class="has-text-centered">93.8</td>
                </tr>
                <tr>
                  <td>w/o RMSNorm</td>
                  <td class="has-text-centered">93.8</td>
                </tr>
                <tr>
                  <td>w/o -inf for invalid tokens</td>
                  <td class="has-text-centered">94.7</td>
                </tr>
                <tr>
                  <td>w/o Softmin SNR</td>
                  <td class="has-text-centered">109.6</td>
                </tr>
                <tr>
                  <td>None (Baseline/AR)</td> <!-- Assuming "None" refers to a baseline -->
                  <td class="has-text-centered">111.2</td>
                </tr>
              </tbody>
            </table>
            <p class="has-text-centered" style="margin-top: 1rem;">
              <b>Table 4.</b> Ablation w/115M parameter model of QK Norm, zero initialization of linear layers, RMSNorm, setting invalid tokens to \(-\infty\) during training and generation, and Softmin SNR.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- New Dataset Visualization Section -->
  <section class="hero is-small pt-5 pb-6 is-light">
    <div class="hero-body">
      <div class="container">
        <h2 id="dataset_visualization" class="title is-3 has-text-centered">
          Dataset Visualization - Reconstruction with VQ16 Tokenizer
          <a href="#dataset_visualization" class="anchor-link">
            <i class="fas fa-link"></i>
          </a>
        </h2>
        <div class="columns is-centered" style="padding-top: 1.5rem;">
          <div class="column is-five-sixths has-text-centered">
            <picture>
              <source srcset="static/images/dataset_tokenizer.png" type="image/png">
              <img src="static/images/dataset_tokenizer.png" alt="Dataset Visualization with Tokenizer">
            </picture>
  
            <p>Reconstruction of samples from the synthetic dataset, encoded from 512x512 with a VQ16 tokenizer.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
  
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
  
          </div>
        </div>
      </div>
    </div>
  </footer>


  <!-- Good lazy loading with animation. For some reason, adding this conflicts with <picture> which is needed to optionally load webp images so for now we add the lazy load attribute (which should be removed when using the below code.) -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
        // Ensure that we wait for all images to be loaded before scrolling to hash
        const images = document.querySelectorAll('img');

        let imagesLoaded = 0;
        const totalImages = images.length;

        images.forEach((img) => {
          if (img.complete) {
            imagesLoaded++;
          } else {
            img.addEventListener('load', function() {
              imagesLoaded++;
              if (imagesLoaded === totalImages) {
                scrollToHash();
              }
            });
            img.addEventListener('error', function() {
              imagesLoaded++;
              if (imagesLoaded === totalImages) {
                scrollToHash();
              }
            });
          }
        });

        // If no images or all images are already loaded
        if (totalImages === 0 || imagesLoaded === totalImages) {
          scrollToHash();
        }

        function scrollToHash() {
          const hash = window.location.hash;
          if (hash) {
            // Use setTimeout to ensure scroll happens after all content is visible
            setTimeout(() => {
              const target = document.querySelector(hash);
              if (target) {
                target.scrollIntoView({ behavior: 'smooth' });
              }
            }, 100);
          }
        }
      });

    $(document).ready(function() {
      $('a.anchor-link').on('click', function(e) {
        e.preventDefault(); // Prevent the default anchor behavior

        // Get the href attribute (e.g., "#abstract")
        var anchor = $(this).attr('href');

        // Construct the full URL with the anchor
        var url = window.location.origin + window.location.pathname + anchor;

        // Copy the URL to the clipboard using the Clipboard API
        if (navigator.clipboard && window.isSecureContext) {
          // navigator.clipboard API method
          navigator.clipboard.writeText(url).then(function() {
            // Success feedback: Change icon to checkmark
            var $icon = $(e.currentTarget).find('i');
            $icon.removeClass('fa-link').addClass('fa-check');

            // Revert back to the original icon after 2 seconds
            setTimeout(function() {
              $icon.removeClass('fa-check').addClass('fa-link');
            }, 2000);
          }, function(err) {
            console.error('Could not copy text: ', err);
            alert('Failed to copy the link. Please try again.');
          });
        } else {
          // Fallback method for older browsers
          var textArea = document.createElement("textarea");
          textArea.value = url;
          // Make the textarea out of viewport
          textArea.style.position = "fixed";
          textArea.style.left = "-999999px";
          document.body.appendChild(textArea);
          textArea.focus();
          textArea.select();
          try {
            document.execCommand('copy');
            // Success feedback: Change icon to checkmark
            var $icon = $(e.currentTarget).find('i');
            $icon.removeClass('fa-link').addClass('fa-check');

            // Revert back to the original icon after 2 seconds
            setTimeout(function() {
              $icon.removeClass('fa-check').addClass('fa-link');
            }, 2000);
          } catch (err) {
            console.error('Fallback: Oops, unable to copy', err);
            alert('Failed to copy the link. Please try manually.');
          }
          document.body.removeChild(textArea);
        }
      });
    });



    document.addEventListener('DOMContentLoaded', function() {
      const images = document.querySelectorAll('img');
      
      images.forEach(img => {
        // Create container
        const container = document.createElement('div');
        container.className = 'progressive-image-container';
        img.parentNode.insertBefore(container, img);
        
        // Create placeholder
        const placeholder = document.createElement('div');
        placeholder.className = 'image-placeholder';
        placeholder.innerHTML = '<div class="spinner"></div>';
        container.appendChild(placeholder);
        
        // Move image into container
        container.appendChild(img);
        img.className += ' progressive-image';
        
        // Load image
        const newImg = new Image();
        newImg.src = img.src;
        newImg.onload = function() {
          img.classList.add('loaded');
          placeholder.style.display = 'none';
        };
      });
    });
  
  </script>

</body>
</html>